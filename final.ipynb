{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225fe03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 11:47:23,780 - INFO - Best hyperparameters: {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 4, 'regressor__max_features': 'sqrt', 'regressor__max_depth': 15}\n",
      "2025-08-09 11:47:23,780 - INFO - Best CV score: 0.9433\n",
      "2025-08-09 11:47:26,735 - ERROR - Error in workflow: 'SolarEnergyPredictor' object has no attribute 'predictions'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SolarEnergyPredictor' object has no attribute 'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 883\u001b[39m\n\u001b[32m    879\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model, predictions\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m     \u001b[43mdemo_solar_energy_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 833\u001b[39m, in \u001b[36mdemo_solar_energy_workflow\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    819\u001b[39m df_with_target = model.create_target_variable(\n\u001b[32m    820\u001b[39m     df_processed, \n\u001b[32m    821\u001b[39m     target_type=\u001b[33m'\u001b[39m\u001b[33menergy_output\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    828\u001b[39m     }\n\u001b[32m    829\u001b[39m )\n\u001b[32m    831\u001b[39m df_final = model.engineer_features(df_with_target)\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m training_results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_final\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m    838\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    840\u001b[39m model.plot_results(training_results, figsize=(\u001b[32m15\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m    842\u001b[39m X_test = training_results[\u001b[33m'\u001b[39m\u001b[33mX_test\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 410\u001b[39m, in \u001b[36mSolarEnergyPredictor.train_model\u001b[39m\u001b[34m(self, df, test_size, optimize_hyperparameters, cv_folds)\u001b[39m\n\u001b[32m    407\u001b[39m y_train_pred = \u001b[38;5;28mself\u001b[39m.pipeline.predict(X_train)\n\u001b[32m    408\u001b[39m y_test_pred = \u001b[38;5;28mself\u001b[39m.pipeline.predict(X_test)\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[38;5;28mself\u001b[39m.metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m cv_scores = cross_val_score(\n\u001b[32m    413\u001b[39m     \u001b[38;5;28mself\u001b[39m.pipeline, X_train, y_train, cv=cv_folds, scoring=\u001b[33m'\u001b[39m\u001b[33mr2\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m    414\u001b[39m )\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._log_model_performance(cv_scores)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 471\u001b[39m, in \u001b[36mSolarEnergyPredictor._calculate_metrics\u001b[39m\u001b[34m(self, y_train, y_train_pred, y_test, y_test_pred)\u001b[39m\n\u001b[32m    469\u001b[39m non_zero_mask = y_test != \u001b[32m0\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.any(non_zero_mask):\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     mape = np.mean(np.abs((y_test[non_zero_mask] - \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictions\u001b[49m[non_zero_mask]) / y_test[non_zero_mask])) * \u001b[32m100\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    473\u001b[39m     mape = np.nan\n",
      "\u001b[31mAttributeError\u001b[39m: 'SolarEnergyPredictor' object has no attribute 'predictions'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('solar_model.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class ModelMetrics:\n",
    "    r2_score: float\n",
    "    mse: float\n",
    "    rmse: float\n",
    "    mae: float\n",
    "    mape: float\n",
    "    accuracy_percentage: float\n",
    "    train_r2: float = None\n",
    "    overfitting_score: float = None\n",
    "\n",
    "class SolarEnergyPredictor:\n",
    "    \n",
    "    def __init__(self, model_type: str = 'random_forest', random_state: int = 42):\n",
    "        self.model_type = model_type\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.pipeline = None\n",
    "        self.feature_names = None\n",
    "        self.target_column = 'solar_energy_output'\n",
    "        self.metrics = None\n",
    "        self.is_trained = False\n",
    "        \n",
    "        self.scaler = RobustScaler()\n",
    "        \n",
    "        self.expected_columns = [\n",
    "            'Year', 'Month', 'Day', 'Hour', 'Minute', 'DHI', 'DNI', 'Dew Point', \n",
    "            'Temperature', 'Pressure', 'Relative Humidity', 'Snow Depth', 'Wind Speed', \n",
    "            'Solar Zenith Angle', 'Precipitable Water', 'Clearsky GHI', 'GHI', \n",
    "            'Clearsky DNI', 'Clearsky DHI'\n",
    "        ]\n",
    "    \n",
    "\n",
    "    def predict_from_user_input(self, user_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Simplified prediction interface that requires only essential parameters.\n",
    "        Automatically fills reasonable defaults for missing parameters.\n",
    "        \n",
    "        Args:\n",
    "            user_data: Dictionary containing at minimum:\n",
    "                - 'Hour' (0-23)\n",
    "                - 'Temperature' (in °C)\n",
    "                - 'Solar Zenith Angle' (degrees)\n",
    "                - 'GHI' (W/m²)\n",
    "                - 'Relative Humidity' (%)\n",
    "                - 'Wind Speed' (m/s)\n",
    "                - 'Month' (1-12)\n",
    "                \n",
    "        Returns:\n",
    "            Prediction results dictionary\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        \n",
    "       \n",
    "        required_params = ['Hour', 'Temperature', 'Solar Zenith Angle', 'GHI',\n",
    "                         'Relative Humidity', 'Wind Speed', 'Month']\n",
    "        missing_params = [p for p in required_params if p not in user_data]\n",
    "        if missing_params:\n",
    "            raise ValueError(f\"Missing required parameters: {missing_params}\")\n",
    "   \n",
    "        defaults = {\n",
    "            'Year': datetime.now().year,\n",
    "            'Day': 15,  \n",
    "            'Minute': 0,\n",
    "            'Pressure': 1013,\n",
    "            'Dew Point': user_data['Temperature'] - 5, \n",
    "            'Snow Depth': 0,\n",
    "            'Precipitable Water': 10,\n",
    "            'DHI': user_data['GHI'] * 0.4, \n",
    "            'DNI': user_data['GHI'] * 0.6, \n",
    "            'Clearsky GHI': user_data['GHI'] * 1.1,\n",
    "            'Clearsky DHI': user_data['GHI'] * 0.4,\n",
    "            'Clearsky DNI': user_data['GHI'] * 0.7\n",
    "        }\n",
    "        \n",
    "       \n",
    "        complete_data = {**defaults, **user_data}\n",
    "        \n",
    "       \n",
    "        input_df = pd.DataFrame([complete_data])\n",
    "        \n",
    "      \n",
    "        processed_input = self.preprocess_data(input_df)\n",
    "        processed_input = self.engineer_features(processed_input)\n",
    "        \n",
    "       \n",
    "        return self.predict(processed_input)\n",
    "    \n",
    "    def load_data(self, file_path: Union[str, Path]) -> pd.DataFrame:\n",
    "        try:\n",
    "            file_path = Path(file_path)\n",
    "            if not file_path.exists():\n",
    "                raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "            \n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            missing_cols = set(self.expected_columns) - set(df.columns)\n",
    "            if missing_cols:\n",
    "                logger.warning(f\"Missing expected columns: {missing_cols}\")\n",
    "            \n",
    "            if df.empty:\n",
    "                raise ValueError(\"Dataset is empty\")\n",
    "            \n",
    "            missing_stats = df.isnull().sum()\n",
    "            missing_count = missing_stats[missing_stats > 0]\n",
    "            if not missing_count.empty:\n",
    "                logger.warning(f\"Missing values found:\\n{missing_count}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        self._handle_missing_values(df_processed)\n",
    "        df_processed = self._create_datetime_features_fast(df_processed)\n",
    "        df_processed = self._clean_solar_data(df_processed)\n",
    "        df_processed = self._clean_weather_data(df_processed)\n",
    "        \n",
    "        return df_processed\n",
    "    \n",
    "    def _handle_missing_values(self, df: pd.DataFrame):\n",
    "        solar_cols = ['GHI', 'DHI', 'DNI', 'Clearsky GHI', 'Clearsky DHI', 'Clearsky DNI']\n",
    "        for col in solar_cols:\n",
    "            if col in df.columns and df[col].isnull().sum() > 0:\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "        \n",
    "        weather_numeric_cols = ['Temperature', 'Pressure', 'Relative Humidity', \n",
    "                               'Wind Speed', 'Dew Point', 'Precipitable Water']\n",
    "        for col in weather_numeric_cols:\n",
    "            if col in df.columns and df[col].isnull().sum() > 0:\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "        \n",
    "        if 'Snow Depth' in df.columns:\n",
    "            df['Snow Depth'].fillna(0, inplace=True)\n",
    "        \n",
    "        if 'Solar Zenith Angle' in df.columns and df['Solar Zenith Angle'].isnull().sum() > 0:\n",
    "            df['Solar Zenith Angle'].fillna(df['Solar Zenith Angle'].median(), inplace=True)\n",
    "    \n",
    "    def _create_datetime_features_fast(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        try:\n",
    "            df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour', 'Minute']])\n",
    "            \n",
    "            df['day_of_year'] = df['datetime'].dt.dayofyear\n",
    "            df['is_weekend'] = (df['datetime'].dt.dayofweek >= 5).astype(int)\n",
    "            \n",
    "            df['hour_angle'] = (df['Hour'] + df['Minute']/60 - 12) * 15\n",
    "            df['solar_elevation_approx'] = 90 - df.get('Solar Zenith Angle', 0)\n",
    "            \n",
    "            df['season'] = df['Month'].map({\n",
    "                12: 0, 1: 0, 2: 0,\n",
    "                3: 1, 4: 1, 5: 1,\n",
    "                6: 2, 7: 2, 8: 2,\n",
    "                9: 3, 10: 3, 11: 3\n",
    "            })\n",
    "            \n",
    "        \n",
    "            df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)\n",
    "            df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)\n",
    "            df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
    "            df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "            \n",
    "           \n",
    "            df['IsDaylight'] = ((df['Hour'] >= 6) & (df['Hour'] <= 18)).astype(int)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not create datetime features: {e}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _clean_solar_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        solar_cols = ['GHI', 'DHI', 'DNI', 'Clearsky GHI', 'Clearsky DHI', 'Clearsky DNI']\n",
    "        \n",
    "        for col in solar_cols:\n",
    "            if col in df.columns:\n",
    "                negative_mask = df[col] < 0\n",
    "                if negative_mask.sum() > 0:\n",
    "                    df.loc[negative_mask, col] = 0\n",
    "                \n",
    "                if 'GHI' in col:\n",
    "                    high_mask = df[col] > 1400\n",
    "                    if high_mask.sum() > 0:\n",
    "                        df.loc[high_mask, col] = 1400\n",
    "                \n",
    "                elif 'DNI' in col:\n",
    "                    high_mask = df[col] > 1000\n",
    "                    if high_mask.sum() > 0:\n",
    "                        df.loc[high_mask, col] = 1000\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _clean_weather_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        bounds = {\n",
    "            'Temperature': (-50, 60),\n",
    "            'Relative Humidity': (0, 100),\n",
    "            'Pressure': (900, 1100),\n",
    "            'Wind Speed': (0, 50),\n",
    "            'Dew Point': (-60, 50),\n",
    "            'Snow Depth': (0, 1000),\n",
    "            'Solar Zenith Angle': (0, 180),\n",
    "            'Precipitable Water': (0, 100)\n",
    "        }\n",
    "        \n",
    "        for col, (min_val, max_val) in bounds.items():\n",
    "            if col in df.columns:\n",
    "                outliers = (df[col] < min_val) | (df[col] > max_val)\n",
    "                if outliers.sum() > 0:\n",
    "                    df[col] = np.clip(df[col], min_val, max_val)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_target_variable(self, df: pd.DataFrame, target_type: str = 'energy_output',\n",
    "                             panel_specs: Dict = None) -> pd.DataFrame:\n",
    "        df_with_target = df.copy()\n",
    "        \n",
    "        if panel_specs is None:\n",
    "            panel_specs = {\n",
    "                'panel_area': 20,\n",
    "                'panel_efficiency': 0.20,\n",
    "                'system_efficiency': 0.85,\n",
    "                'temperature_coefficient': -0.004,\n",
    "                'optimal_temperature': 25\n",
    "            }\n",
    "        \n",
    "        if target_type == 'energy_output':\n",
    "            solar_energy = self._calculate_energy_output(df_with_target, panel_specs)\n",
    "        elif target_type == 'ghi_prediction':\n",
    "            solar_energy = self._create_ghi_prediction_target(df_with_target) #this part can be removed\n",
    "        elif target_type == 'efficiency_index':\n",
    "            solar_energy = self._calculate_efficiency_index(df_with_target)\n",
    "        else:\n",
    "            raise ValueError(\"target_type must be 'energy_output', 'ghi_prediction', or 'efficiency_index'\")\n",
    "        \n",
    "        df_with_target[self.target_column] = solar_energy\n",
    "        \n",
    "        return df_with_target\n",
    "    \n",
    "    def _calculate_energy_output(self, df: pd.DataFrame, panel_specs: Dict) -> np.ndarray:\n",
    "        if 'GHI' not in df.columns:\n",
    "            raise ValueError(\"GHI column required for energy output calculation\")\n",
    "        \n",
    "        base_energy = (df['GHI'] * panel_specs['panel_area'] * \n",
    "                      panel_specs['panel_efficiency'] / 1000)\n",
    "        \n",
    "        if 'Temperature' in df.columns:\n",
    "            temp_factor = 1 + panel_specs['temperature_coefficient'] * \\\n",
    "                         (df['Temperature'] - panel_specs['optimal_temperature'])\n",
    "            temp_factor = np.clip(temp_factor, 0.6, 1.2)\n",
    "            base_energy *= temp_factor\n",
    "        \n",
    "        energy_output = base_energy * panel_specs['system_efficiency']\n",
    "        \n",
    "        if 'Snow Depth' in df.columns:\n",
    "            snow_factor = np.where(df['Snow Depth'] > 0, \n",
    "                                 np.maximum(0.1, 1 - df['Snow Depth'] / 100), 1)\n",
    "            energy_output *= snow_factor\n",
    "        \n",
    "        if 'Wind Speed' in df.columns:\n",
    "            wind_factor = 1 + np.minimum(0.05, df['Wind Speed'] / 100)\n",
    "            energy_output *= wind_factor\n",
    "        \n",
    "        if 'Solar Zenith Angle' in df.columns:\n",
    "            angle_factor = np.where(df['Solar Zenith Angle'] > 75, \n",
    "                                   np.maximum(0.1, 1 - (df['Solar Zenith Angle'] - 75) / 50), 1)\n",
    "            energy_output *= angle_factor\n",
    "        \n",
    "        noise_factor = np.random.normal(1.0, 0.015, len(df))\n",
    "        energy_output *= noise_factor\n",
    "        \n",
    "        energy_output = np.maximum(0, energy_output)\n",
    "        \n",
    "        return energy_output\n",
    "    \n",
    "    def _create_ghi_prediction_target(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        if 'GHI' not in df.columns:\n",
    "            raise ValueError(\"GHI column required for GHI prediction target\") #This can be removed\n",
    "        \n",
    "        ghi_target = df['GHI'].copy()\n",
    "        if len(df) > 1:\n",
    "            ghi_target = df['GHI'].shift(-1).fillna(df['GHI'])\n",
    "        \n",
    "        return ghi_target.values\n",
    "    \n",
    "    def _calculate_efficiency_index(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        required_cols = ['GHI', 'Clearsky GHI']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            raise ValueError(f\"Columns {required_cols} required for efficiency index\")\n",
    "        \n",
    "        efficiency_index = df['GHI'] / (df['Clearsky GHI'] + 1e-6)\n",
    "        \n",
    "        weather_penalty = 0\n",
    "        if 'Relative Humidity' in df.columns:\n",
    "            weather_penalty += (df['Relative Humidity'] / 100) * 0.1\n",
    "        \n",
    "        efficiency_index = efficiency_index * (1 - weather_penalty)\n",
    "        efficiency_index = np.clip(efficiency_index, 0, 1.5)\n",
    "        \n",
    "        return efficiency_index * 100\n",
    "    \n",
    "    def engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_engineered = df.copy()\n",
    "        \n",
    "        # Drop columns we won't use\n",
    "        cols_to_drop = ['Month', 'Day', 'Hour', 'GHI', 'Clearsky GHI', \n",
    "                       'DHI', 'Clearsky DNI', 'DNI', 'Clearsky DHI']\n",
    "        df_engineered = df_engineered.drop(columns=[col for col in cols_to_drop if col in df_engineered.columns])\n",
    "        \n",
    "        # Create interaction features\n",
    "        if all(col in df_engineered.columns for col in ['Wind Speed', 'Temperature']):\n",
    "            df_engineered['Wind_Temp'] = df_engineered['Wind Speed'] * df_engineered['Temperature']\n",
    "        \n",
    "        if all(col in df_engineered.columns for col in ['Temperature', 'Relative Humidity']):\n",
    "            df_engineered['Temp_RelHumidity'] = df_engineered['Temperature'] * df_engineered['Relative Humidity'] / 100\n",
    "        \n",
    "        if all(col in df_engineered.columns for col in ['Wind Speed', 'Relative Humidity']):\n",
    "            df_engineered['Wind_RelHumidity'] = df_engineered['Wind Speed'] * df_engineered['Relative Humidity']\n",
    "        \n",
    "        return df_engineered\n",
    "    \n",
    "    def train_model(self, df: pd.DataFrame, test_size: float = 0.2, \n",
    "                   optimize_hyperparameters: bool = True, cv_folds: int = 3) -> Dict:\n",
    "        if self.target_column not in df.columns:\n",
    "            raise ValueError(f\"Target column '{self.target_column}' not found in DataFrame\")\n",
    "        \n",
    "        cols_to_drop = ['datetime', 'Year', 'Minute', self.target_column]\n",
    "        feature_cols = [col for col in df.columns if col not in cols_to_drop]\n",
    "        \n",
    "        X = df[feature_cols].copy()\n",
    "        y = df[self.target_column].copy()\n",
    "        \n",
    "        X = X.fillna(X.median())\n",
    "        \n",
    "        self.feature_names = list(X.columns)\n",
    "        \n",
    "        if 'datetime' in df.columns:\n",
    "            sort_idx = df['datetime'].argsort()\n",
    "            n_test = int(len(df) * test_size)\n",
    "            \n",
    "            train_idx = sort_idx[:-n_test]\n",
    "            test_idx = sort_idx[-n_test:]\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=self.random_state\n",
    "            )\n",
    "        \n",
    "        if self.model_type == 'random_forest':\n",
    "            base_model = RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                random_state=self.random_state, \n",
    "                n_jobs=-1\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
    "        \n",
    "        self.pipeline = Pipeline([\n",
    "            ('scaler', self.scaler),\n",
    "            ('regressor', base_model)\n",
    "        ])\n",
    "        \n",
    "        if optimize_hyperparameters:\n",
    "            self.pipeline = self._fast_optimize_hyperparameters(\n",
    "                self.pipeline, X_train, y_train, cv_folds\n",
    "            )\n",
    "        \n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "        self.model = self.pipeline.named_steps['regressor']\n",
    "        self.is_trained = True\n",
    "        \n",
    "        y_train_pred = self.pipeline.predict(X_train)\n",
    "        y_test_pred = self.pipeline.predict(X_test)\n",
    "        \n",
    "        self.metrics = self._calculate_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "        \n",
    "        cv_scores = cross_val_score(\n",
    "            self.pipeline, X_train, y_train, cv=cv_folds, scoring='r2', n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        self._log_model_performance(cv_scores)\n",
    "        \n",
    "        return {\n",
    "            'train_score': self.metrics.train_r2,\n",
    "            'test_score': self.metrics.r2_score,\n",
    "            'cv_scores': cv_scores,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'y_pred': y_test_pred,\n",
    "            'feature_importance': self._get_feature_importance()\n",
    "        }\n",
    "    \n",
    "    def _fast_optimize_hyperparameters(self, pipeline: Pipeline, X_train: pd.DataFrame, \n",
    "                                      y_train: pd.Series, cv_folds: int) -> Pipeline:\n",
    "        if self.model_type == 'random_forest':\n",
    "            param_distributions = {\n",
    "                'regressor__n_estimators': [50, 100, 150],\n",
    "                'regressor__max_depth': [10, 15, 20, None],\n",
    "                'regressor__min_samples_split': [2, 5, 10],\n",
    "                'regressor__min_samples_leaf': [1, 2, 4],\n",
    "                'regressor__max_features': ['sqrt', 'log2']\n",
    "            }\n",
    "        \n",
    "        n_iter = min(12, len(X_train) // 1000)\n",
    "        n_iter = max(n_iter, 6)\n",
    "        \n",
    "        random_search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions,\n",
    "            n_iter=n_iter,\n",
    "            cv=cv_folds,\n",
    "            scoring='r2',\n",
    "            n_jobs=-1,\n",
    "            verbose=0,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        logger.info(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "        logger.info(f\"Best CV score: {random_search.best_score_:.4f}\")\n",
    "        \n",
    "        return random_search.best_estimator_\n",
    "    \n",
    "    def _calculate_metrics(self, y_train: pd.Series, y_train_pred: np.ndarray,\n",
    "                          y_test: pd.Series, y_test_pred: np.ndarray) -> ModelMetrics:\n",
    "        r2 = r2_score(y_test, y_test_pred)\n",
    "        mse = mean_squared_error(y_test, y_test_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        \n",
    "        mape = np.mean(np.abs((y_test - y_test_pred) / (y_test + 1e-8))) * 100\n",
    "        accuracy = max(0, 100 - mape)\n",
    "        \n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        overfitting = train_r2 - r2\n",
    "        \n",
    "        return ModelMetrics(\n",
    "            r2_score=r2,\n",
    "            mse=mse,\n",
    "            rmse=rmse,\n",
    "            mae=mae,\n",
    "            mape=mape,\n",
    "            accuracy_percentage=accuracy,\n",
    "            train_r2=train_r2,\n",
    "            overfitting_score=overfitting\n",
    "        )\n",
    "    \n",
    "    def _get_feature_importance(self) -> pd.DataFrame:\n",
    "        if not self.is_trained or not hasattr(self.model, 'feature_importances_'):\n",
    "            return None\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': self.feature_names,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    def _log_model_performance(self, cv_scores: np.ndarray):\n",
    "        logger.info(\"=\"*70)\n",
    "        logger.info(\"SOLAR ENERGY MODEL PERFORMANCE SUMMARY\")\n",
    "        logger.info(\"=\"*70)\n",
    "        logger.info(f\"Model Type: {self.model_type.upper()}\")\n",
    "        logger.info(f\"Test R² Score: {self.metrics.r2_score:.4f}\")\n",
    "        logger.info(f\"Test RMSE: {self.metrics.rmse:.2f}\")\n",
    "        logger.info(f\"Test MAE: {self.metrics.mae:.2f}\")\n",
    "        logger.info(f\"Test MAPE: {self.metrics.mape:.2f}%\")\n",
    "        logger.info(f\"Model Accuracy: {self.metrics.accuracy_percentage:.2f}%\")\n",
    "        logger.info(f\"Cross-validation R²: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "        \n",
    "        if self.metrics.r2_score >= 0.9:\n",
    "            performance = \"EXCELLENT\"\n",
    "        elif self.metrics.r2_score >= 0.8:\n",
    "            performance = \"VERY GOOD\" \n",
    "        elif self.metrics.r2_score >= 0.7:\n",
    "            performance = \"GOOD\"\n",
    "        elif self.metrics.r2_score >= 0.6:\n",
    "            performance = \"FAIR\"\n",
    "        else:\n",
    "            performance = \"NEEDS IMPROVEMENT\"\n",
    "        \n",
    "        logger.info(f\"Performance Level: {performance}\")\n",
    "        \n",
    "        if self.metrics.overfitting_score > 0.15:\n",
    "            logger.warning(f\"HIGH overfitting detected (gap: {self.metrics.overfitting_score:.4f})\")\n",
    "        elif self.metrics.overfitting_score > 0.05:\n",
    "            logger.warning(f\"MILD overfitting detected (gap: {self.metrics.overfitting_score:.4f})\")\n",
    "        else:\n",
    "            logger.info(f\"Good generalization (train-test gap: {self.metrics.overfitting_score:.4f})\")\n",
    "        \n",
    "        logger.info(\"=\"*70)\n",
    "    \n",
    "    def predict(self, X_new: pd.DataFrame, return_confidence: bool = True) -> Dict:\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        \n",
    "        X_pred = self._prepare_prediction_features(X_new)\n",
    "        \n",
    "        predictions = self.pipeline.predict(X_pred)\n",
    "        \n",
    "        results = {\n",
    "            'predictions': predictions,\n",
    "            'input_data': X_new,\n",
    "            'features_used': X_pred\n",
    "        }\n",
    "        \n",
    "        if return_confidence and hasattr(self.model, 'estimators_'):\n",
    "            confidence_info = self._calculate_prediction_confidence(X_pred, predictions)\n",
    "            results.update(confidence_info)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _prepare_prediction_features(self, X_new: pd.DataFrame) -> pd.DataFrame:\n",
    "        missing_features = set(self.feature_names) - set(X_new.columns)\n",
    "        if missing_features:\n",
    "            logger.warning(f\"Missing features: {missing_features}\")\n",
    "            \n",
    "            for feature in missing_features:\n",
    "                if any(x in feature.lower() for x in ['_ma', '_ratio', '_diff']):\n",
    "                    X_new[feature] = 0\n",
    "                elif 'temperature' in feature.lower():\n",
    "                    X_new[feature] = 20\n",
    "                elif 'humidity' in feature.lower():\n",
    "                    X_new[feature] = 60\n",
    "                elif 'pressure' in feature.lower():\n",
    "                    X_new[feature] = 1013\n",
    "                elif 'wind' in feature.lower():\n",
    "                    X_new[feature] = 3\n",
    "                else:\n",
    "                    X_new[feature] = 0\n",
    "        \n",
    "        X_pred = X_new[self.feature_names].copy()\n",
    "        X_pred = X_pred.fillna(X_pred.median())\n",
    "        \n",
    "        return X_pred\n",
    "    \n",
    "    def _calculate_prediction_confidence(self, X_pred: pd.DataFrame, predictions: np.ndarray) -> Dict:\n",
    "        fitted_scaler = self.pipeline.named_steps['scaler']\n",
    "        \n",
    "        tree_predictions = np.array([\n",
    "            tree.predict(fitted_scaler.transform(X_pred)) \n",
    "            for tree in self.model.estimators_\n",
    "        ])\n",
    "        \n",
    "        prediction_std = np.std(tree_predictions, axis=0)\n",
    "        prediction_var = np.var(tree_predictions, axis=0)\n",
    "        \n",
    "        confidence_intervals = 1.96 * prediction_std\n",
    "        \n",
    "        max_std = np.max(prediction_std) + 1e-8\n",
    "        confidence_scores = 100 * (1 - (prediction_std / max_std))\n",
    "        confidence_scores = np.clip(confidence_scores, 0, 100)\n",
    "        \n",
    "        lower_bounds = predictions - confidence_intervals\n",
    "        upper_bounds = predictions + confidence_intervals\n",
    "        \n",
    "        return {\n",
    "            'confidence_scores': confidence_scores,\n",
    "            'prediction_std': prediction_std,\n",
    "            'prediction_variance': prediction_var,\n",
    "            'confidence_intervals': confidence_intervals,\n",
    "            'lower_bounds': lower_bounds,\n",
    "            'upper_bounds': upper_bounds\n",
    "        }\n",
    "    \n",
    "    def plot_results(self, training_results: Dict, figsize: Tuple[int, int] = (15, 10)):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before plotting results\")\n",
    "        \n",
    "        y_test = training_results['y_test']\n",
    "        y_pred = training_results['y_pred']\n",
    "        feature_importance = training_results.get('feature_importance')\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
    "        fig.suptitle(f'Solar Energy Prediction Model Results ({self.model_type.title()})', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes[0, 0].scatter(y_test, y_pred, alpha=0.6, s=20, c='orange')\n",
    "        axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "        axes[0, 0].set_xlabel('Actual Solar Energy Output')\n",
    "        axes[0, 0].set_ylabel('Predicted Solar Energy Output')\n",
    "        axes[0, 0].set_title(f'Actual vs Predicted (R² = {self.metrics.r2_score:.3f})')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        residuals = y_test - y_pred\n",
    "        axes[0, 1].scatter(y_pred, residuals, alpha=0.6, s=20, c='lightblue')\n",
    "        axes[0, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "        axes[0, 1].set_xlabel('Predicted Solar Energy Output')\n",
    "        axes[0, 1].set_ylabel('Residuals')\n",
    "        axes[0, 1].set_title('Residuals Plot')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[0, 2].hist(residuals, bins=30, alpha=0.7, color='lightgreen')\n",
    "        axes[0, 2].axvline(residuals.mean(), color='red', linestyle='--', linewidth=2,\n",
    "                          label=f'Mean: {residuals.mean():.2f}')\n",
    "        axes[0, 2].set_xlabel('Prediction Errors')\n",
    "        axes[0, 2].set_ylabel('Frequency')\n",
    "        axes[0, 2].set_title('Error Distribution')\n",
    "        axes[0, 2].legend()\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        if feature_importance is not None:\n",
    "            top_features = feature_importance.head(10)\n",
    "            y_pos = np.arange(len(top_features))\n",
    "            axes[1, 0].barh(y_pos, top_features['importance'], color='forestgreen', alpha=0.8)\n",
    "            axes[1, 0].set_yticks(y_pos)\n",
    "            axes[1, 0].set_yticklabels(top_features['feature'], fontsize=8)\n",
    "            axes[1, 0].set_xlabel('Feature Importance')\n",
    "            axes[1, 0].set_title('Top 10 Feature Importances')\n",
    "            axes[1, 0].invert_yaxis()\n",
    "            axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        cv_scores = training_results['cv_scores']\n",
    "        axes[1, 1].bar(range(len(cv_scores)), cv_scores, alpha=0.8, color='orange')\n",
    "        axes[1, 1].axhline(cv_scores.mean(), color='red', linestyle='--', linewidth=2,\n",
    "                          label=f'Mean: {cv_scores.mean():.3f}')\n",
    "        axes[1, 1].set_xlabel('CV Fold')\n",
    "        axes[1, 1].set_ylabel('R² Score')\n",
    "        axes[1, 1].set_title('Cross-Validation Scores')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1, 2].axis('off')\n",
    "        metrics_text = f\"\"\"\n",
    "MODEL PERFORMANCE\n",
    "\n",
    "R² Score: {self.metrics.r2_score:.4f}\n",
    "RMSE: {self.metrics.rmse:.2f}\n",
    "MAE: {self.metrics.mae:.2f}\n",
    "MAPE: {self.metrics.mape:.2f}%\n",
    "Accuracy: {self.metrics.accuracy_percentage:.2f}%\n",
    "\n",
    "Cross-Validation:\n",
    "   Mean R²: {cv_scores.mean():.4f}\n",
    "   Std R²: {cv_scores.std():.4f}\n",
    "\n",
    "Overfitting Check:\n",
    "   Train R²: {self.metrics.train_r2:.4f}\n",
    "   Test R²: {self.metrics.r2_score:.4f}\n",
    "   Gap: {self.metrics.overfitting_score:.4f}\n",
    "        \"\"\"\n",
    "        \n",
    "        axes[1, 2].text(0.05, 0.95, metrics_text, transform=axes[1, 2].transAxes, \n",
    "                        fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
    "        axes[1, 2].set_title('Performance Summary')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def load_model(self, filepath: Union[str, Path]):\n",
    "        filepath = Path(filepath)\n",
    "        \n",
    "        model_path = filepath.with_suffix('.pkl')\n",
    "        if not model_path.exists():\n",
    "            raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "        \n",
    "        self.pipeline = joblib.load(model_path)\n",
    "        self.model = self.pipeline.named_steps['regressor']\n",
    "        self.scaler = self.pipeline.named_steps['scaler']\n",
    "        \n",
    "        info_path = filepath.with_suffix('.json')\n",
    "        if info_path.exists():\n",
    "            import json\n",
    "            with open(info_path, 'r') as f:\n",
    "                model_info = json.load(f)\n",
    "            \n",
    "            self.model_type = model_info['model_type']\n",
    "            self.feature_names = model_info['feature_names']\n",
    "            self.target_column = model_info['target_column']\n",
    "            \n",
    "            if model_info['metrics']:\n",
    "                metrics_dict = model_info['metrics']\n",
    "                self.metrics = ModelMetrics(\n",
    "                    r2_score=metrics_dict['r2_score'],\n",
    "                    mse=0,\n",
    "                    rmse=metrics_dict['rmse'],\n",
    "                    mae=metrics_dict['mae'],\n",
    "                    mape=metrics_dict['mape'],\n",
    "                    accuracy_percentage=metrics_dict['accuracy_percentage']\n",
    "                )\n",
    "        \n",
    "        self.is_trained = True\n",
    "        logger.info(f\"Model loaded from {model_path}\")\n",
    "    \n",
    "    def generate_prediction_report(self, prediction_results: Dict, \n",
    "                                 output_file: Optional[str] = None) -> str:\n",
    "        predictions = prediction_results['predictions']\n",
    "        input_data = prediction_results['input_data']\n",
    "        \n",
    "        report_lines = [\n",
    "            \"=\"*80,\n",
    "            \"SOLAR ENERGY PREDICTION REPORT\",\n",
    "            \"=\"*80,\n",
    "            f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "            f\"Model Type: {self.model_type.title()}\",\n",
    "            f\"Target: Solar Energy Output (kWh)\",\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        if self.metrics:\n",
    "            report_lines.extend([\n",
    "                \"MODEL PERFORMANCE:\",\n",
    "                \"-\" * 50,\n",
    "                f\"R² Score: {self.metrics.r2_score:.4f}\",\n",
    "                f\"RMSE: {self.metrics.rmse:.2f} kWh\",\n",
    "                f\"MAE: {self.metrics.mae:.2f} kWh\",\n",
    "                f\"MAPE: {self.metrics.mape:.2f}%\",\n",
    "                f\"Accuracy: {self.metrics.accuracy_percentage:.2f}%\",\n",
    "                \"\"\n",
    "            ])\n",
    "        \n",
    "        report_lines.extend([\n",
    "            \"PREDICTION SUMMARY:\",\n",
    "            \"-\" * 50,\n",
    "            f\"Number of predictions: {len(predictions)}\",\n",
    "            f\"Average predicted energy: {predictions.mean():.2f} kWh\",\n",
    "            f\"Energy range: {predictions.min():.2f} - {predictions.max():.2f} kWh\",\n",
    "            f\"Standard deviation: {predictions.std():.2f} kWh\",\n",
    "            f\"Total predicted energy: {predictions.sum():.2f} kWh\",\n",
    "            \"\"\n",
    "        ])\n",
    "        \n",
    "        n_show = min(10, len(predictions))\n",
    "        report_lines.extend([\n",
    "            f\"SAMPLE PREDICTIONS (showing first {n_show}):\",\n",
    "            \"-\" * 50\n",
    "        ])\n",
    "        \n",
    "        for i in range(n_show):\n",
    "            pred = predictions[i]\n",
    "            line = f\"Sample {i+1:3d}: {pred:7.2f} kWh\"\n",
    "            \n",
    "            if 'confidence_scores' in prediction_results:\n",
    "                conf = prediction_results['confidence_scores'][i]\n",
    "                line += f\" (Confidence: {conf:5.1f}%)\"\n",
    "            \n",
    "            report_lines.append(line)\n",
    "        \n",
    "        if len(predictions) > n_show:\n",
    "            report_lines.append(f\"... and {len(predictions) - n_show} more predictions\")\n",
    "        \n",
    "        report_lines.extend([\n",
    "            \"\",\n",
    "            \"PERFORMANCE INSIGHTS:\",\n",
    "            \"-\" * 50\n",
    "        ])\n",
    "        \n",
    "        if self.metrics:\n",
    "            if self.metrics.r2_score >= 0.9:\n",
    "                report_lines.append(\"EXCELLENT model performance\")\n",
    "            elif self.metrics.r2_score >= 0.8:\n",
    "                report_lines.append(\"VERY GOOD model performance\")\n",
    "            elif self.metrics.r2_score >= 0.7:\n",
    "                report_lines.append(\"GOOD model performance\")\n",
    "            else:\n",
    "                report_lines.append(\"FAIR model performance\")\n",
    "        \n",
    "        report_lines.append(\"=\"*80)\n",
    "        \n",
    "        report = \"\\n\".join(report_lines)\n",
    "        \n",
    "        if output_file:\n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write(report)\n",
    "            logger.info(f\"Report saved to {output_file}\")\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "def demo_solar_energy_workflow():\n",
    "    model = SolarEnergyPredictor(model_type='random_forest', random_state=42)\n",
    "    \n",
    "    try:\n",
    "        df = model.load_data('D:\\pict_ml_project\\Solar_DataSet_Techfest(1).csv')\n",
    "        \n",
    "        df_processed = model.preprocess_data(df)\n",
    "        \n",
    "        df_with_target = model.create_target_variable(\n",
    "            df_processed, \n",
    "            target_type='energy_output',\n",
    "            panel_specs={\n",
    "                'panel_area': 25,\n",
    "                'panel_efficiency': 0.21,\n",
    "                'system_efficiency': 0.87,\n",
    "                'temperature_coefficient': -0.0038,\n",
    "                'optimal_temperature': 25\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        df_final = model.engineer_features(df_with_target)\n",
    "        \n",
    "        training_results = model.train_model(\n",
    "            df_final,\n",
    "            test_size=0.2,\n",
    "            optimize_hyperparameters=True,\n",
    "            cv_folds=3\n",
    "        )\n",
    "        \n",
    "        model.plot_results(training_results, figsize=(15, 10))\n",
    "        \n",
    "        X_test = training_results['X_test']\n",
    "        sample_data = X_test.head(100)\n",
    "        \n",
    "        prediction_results = model.predict(sample_data, return_confidence=True)\n",
    "        \n",
    "        report = model.generate_prediction_report(prediction_results)\n",
    "        print(report)\n",
    "        \n",
    "        return model, training_results, prediction_results\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"DATASET FILE NOT FOUND!\")\n",
    "        print(\"Ensure 'Solar_DataSet_Techfest(1).csv' is in the current directory\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in workflow: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def quick_train(csv_file_path: str, sample_predictions: int = 5):\n",
    "    model = SolarEnergyPredictor(model_type='random_forest')\n",
    "    \n",
    "    df = model.load_data(csv_file_path)\n",
    "    df_processed = model.preprocess_data(df)\n",
    "    df_with_target = model.create_target_variable(df_processed, target_type='energy_output')\n",
    "    df_final = model.engineer_features(df_with_target)\n",
    "    \n",
    "    results = model.train_model(df_final, optimize_hyperparameters=False, cv_folds=3)\n",
    "    \n",
    "    X_test = results['X_test']\n",
    "    sample_data = X_test.head(100)\n",
    "    predictions = model.predict(sample_data, return_confidence=False)\n",
    "    \n",
    "    print(f\"Model R² Score: {model.metrics.r2_score:.3f}\")\n",
    "    print(f\"Model Accuracy: {model.metrics.accuracy_percentage:.1f}%\")\n",
    "    print(f\"Sample Predictions: {predictions['predictions'][:sample_predictions]}\")\n",
    "    \n",
    "    return model, predictions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_solar_energy_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02d32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f7ebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pipeline saved to: saved_models\\solar_model_20250807_222145.pkl\n",
      "Model info saved to: saved_models\\solar_model_20250807_222145.json\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model_pipeline(model, model_type: str, feature_names: list, \n",
    "                       target_column: str, metrics=None, \n",
    "                       output_dir: str = 'saved_models'):\n",
    "    \"\"\"\n",
    "    Save the trained model pipeline to a PKL file along with metadata.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model pipeline\n",
    "        model_type: Type of model ('random_forest' or 'gradient_boosting')\n",
    "        feature_names: List of feature names used in training\n",
    "        target_column: Name of the target column\n",
    "        metrics: ModelMetrics object containing performance metrics\n",
    "        output_dir: Directory to save the model files\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generate timestamp for filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_filename = f\"solar_model_{timestamp}.pkl\"\n",
    "    info_filename = f\"solar_model_{timestamp}.json\"\n",
    "    \n",
    "    # Save the model pipeline\n",
    "    model_path = Path(output_dir) / model_filename\n",
    "    joblib.dump(model, model_path)\n",
    "    \n",
    "    # Prepare metadata to save\n",
    "    model_info = {\n",
    "        'model_type': model_type,\n",
    "        'feature_names': feature_names,\n",
    "        'target_column': target_column,\n",
    "        'saved_at': timestamp,\n",
    "        'metrics': None\n",
    "    }\n",
    "    \n",
    "    if metrics:\n",
    "        model_info['metrics'] = {\n",
    "            'r2_score': metrics.r2_score,\n",
    "            'rmse': metrics.rmse,\n",
    "            'mae': metrics.mae,\n",
    "            'mape': metrics.mape,\n",
    "            'accuracy_percentage': metrics.accuracy_percentage,\n",
    "            'train_r2': metrics.train_r2,\n",
    "            'overfitting_score': metrics.overfitting_score\n",
    "        }\n",
    "    \n",
    "    # Save the model info\n",
    "    info_path = Path(output_dir) / info_filename\n",
    "    with open(info_path, 'w') as f:\n",
    "        json.dump(model_info, f, indent=4)\n",
    "    \n",
    "    print(f\"Model pipeline saved to: {model_path}\")\n",
    "    print(f\"Model info saved to: {info_path}\")\n",
    "    \n",
    "    return model_path, info_path\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a trained model from the SolarEnergyPredictor class\n",
    "if __name__ == \"__main__\":\n",
    "    # First train your model using the SolarEnergyPredictor\n",
    "    model_predictor = SolarEnergyPredictor(model_type='random_forest')\n",
    "    # ... (your training code here) ...\n",
    "    \n",
    "    # Then save the trained pipeline\n",
    "    save_model_pipeline(\n",
    "        model=model_predictor.pipeline,\n",
    "        model_type=model_predictor.model_type,\n",
    "        feature_names=model_predictor.feature_names,\n",
    "        target_column=model_predictor.target_column,\n",
    "        metrics=model_predictor.metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8593dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 12:08:05,153 - INFO - Best hyperparameters: {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 4, 'regressor__max_features': 'sqrt', 'regressor__max_depth': 15}\n",
      "2025-08-09 12:08:05,153 - INFO - Best CV score: 0.9434\n",
      "2025-08-09 12:08:08,252 - ERROR - Error in workflow: ModelMetrics.__init__() missing 1 required positional argument: 'accuracy_percentage'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ModelMetrics.__init__() missing 1 required positional argument: 'accuracy_percentage'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 885\u001b[39m\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model, predictions\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     \u001b[43mdemo_solar_energy_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 835\u001b[39m, in \u001b[36mdemo_solar_energy_workflow\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    821\u001b[39m df_with_target = model.create_target_variable(\n\u001b[32m    822\u001b[39m     df_processed, \n\u001b[32m    823\u001b[39m     target_type=\u001b[33m'\u001b[39m\u001b[33menergy_output\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    830\u001b[39m     }\n\u001b[32m    831\u001b[39m )\n\u001b[32m    833\u001b[39m df_final = model.engineer_features(df_with_target)\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m training_results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_final\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m model.plot_results(training_results, figsize=(\u001b[32m15\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m    844\u001b[39m X_test = training_results[\u001b[33m'\u001b[39m\u001b[33mX_test\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 410\u001b[39m, in \u001b[36mSolarEnergyPredictor.train_model\u001b[39m\u001b[34m(self, df, test_size, optimize_hyperparameters, cv_folds)\u001b[39m\n\u001b[32m    407\u001b[39m y_train_pred = \u001b[38;5;28mself\u001b[39m.pipeline.predict(X_train)\n\u001b[32m    408\u001b[39m y_test_pred = \u001b[38;5;28mself\u001b[39m.pipeline.predict(X_test)\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[38;5;28mself\u001b[39m.metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m cv_scores = cross_val_score(\n\u001b[32m    413\u001b[39m     \u001b[38;5;28mself\u001b[39m.pipeline, X_train, y_train, cv=cv_folds, scoring=\u001b[33m'\u001b[39m\u001b[33mr2\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m    414\u001b[39m )\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._log_model_performance(cv_scores)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 480\u001b[39m, in \u001b[36mSolarEnergyPredictor._calculate_metrics\u001b[39m\u001b[34m(self, y_train, y_train_pred, y_test, y_test_pred)\u001b[39m\n\u001b[32m    477\u001b[39m train_r2 = r2_score(y_train, y_train_pred)\n\u001b[32m    478\u001b[39m overfitting = train_r2 - r2\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModelMetrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43mr2_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mr2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrmse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrmse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmae\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_r2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_r2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverfitting_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverfitting\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: ModelMetrics.__init__() missing 1 required positional argument: 'accuracy_percentage'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('solar_model.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class ModelMetrics:\n",
    "    r2_score: float\n",
    "    mse: float\n",
    "    rmse: float\n",
    "    mae: float\n",
    "    mape: float\n",
    "    accuracy_percentage: float\n",
    "    train_r2: float = None\n",
    "    overfitting_score: float = None\n",
    "\n",
    "class SolarEnergyPredictor:\n",
    "    \n",
    "    def __init__(self, model_type: str = 'random_forest', random_state: int = 42):\n",
    "        self.model_type = model_type\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.pipeline = None\n",
    "        self.feature_names = None\n",
    "        self.target_column = 'solar_energy_output'\n",
    "        self.metrics = None\n",
    "        self.is_trained = False\n",
    "        \n",
    "        self.scaler = RobustScaler()\n",
    "        \n",
    "        self.expected_columns = [\n",
    "            'Year', 'Month', 'Day', 'Hour', 'Minute', 'DHI', 'DNI', 'Dew Point', \n",
    "            'Temperature', 'Pressure', 'Relative Humidity', 'Snow Depth', 'Wind Speed', \n",
    "            'Solar Zenith Angle', 'Precipitable Water', 'Clearsky GHI', 'GHI', \n",
    "            'Clearsky DNI', 'Clearsky DHI'\n",
    "        ]\n",
    "    \n",
    "\n",
    "    def predict_from_user_input(self, user_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Simplified prediction interface that requires only essential parameters.\n",
    "        Automatically fills reasonable defaults for missing parameters.\n",
    "        \n",
    "        Args:\n",
    "            user_data: Dictionary containing at minimum:\n",
    "                - 'Hour' (0-23)\n",
    "                - 'Temperature' (in °C)\n",
    "                - 'Solar Zenith Angle' (degrees)\n",
    "                - 'GHI' (W/m²)\n",
    "                - 'Relative Humidity' (%)\n",
    "                - 'Wind Speed' (m/s)\n",
    "                - 'Month' (1-12)\n",
    "                \n",
    "        Returns:\n",
    "            Prediction results dictionary\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        \n",
    "       \n",
    "        required_params = ['Hour', 'Temperature', 'Solar Zenith Angle', 'GHI',\n",
    "                         'Relative Humidity', 'Wind Speed', 'Month']\n",
    "        missing_params = [p for p in required_params if p not in user_data]\n",
    "        if missing_params:\n",
    "            raise ValueError(f\"Missing required parameters: {missing_params}\")\n",
    "   \n",
    "        defaults = {\n",
    "            'Year': datetime.now().year,\n",
    "            'Day': 15,  \n",
    "            'Minute': 0,\n",
    "            'Pressure': 1013,\n",
    "            'Dew Point': user_data['Temperature'] - 5, \n",
    "            'Snow Depth': 0,\n",
    "            'Precipitable Water': 10,\n",
    "            'DHI': user_data['GHI'] * 0.4, \n",
    "            'DNI': user_data['GHI'] * 0.6, \n",
    "            'Clearsky GHI': user_data['GHI'] * 1.1,\n",
    "            'Clearsky DHI': user_data['GHI'] * 0.4,\n",
    "            'Clearsky DNI': user_data['GHI'] * 0.7\n",
    "        }\n",
    "        \n",
    "       \n",
    "        complete_data = {**defaults, **user_data}\n",
    "        \n",
    "       \n",
    "        input_df = pd.DataFrame([complete_data])\n",
    "        \n",
    "      \n",
    "        processed_input = self.preprocess_data(input_df)\n",
    "        processed_input = self.engineer_features(processed_input)\n",
    "        \n",
    "       \n",
    "        return self.predict(processed_input)\n",
    "    \n",
    "    def load_data(self, file_path: Union[str, Path]) -> pd.DataFrame:\n",
    "        try:\n",
    "            file_path = Path(file_path)\n",
    "            if not file_path.exists():\n",
    "                raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "            \n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            missing_cols = set(self.expected_columns) - set(df.columns)\n",
    "            if missing_cols:\n",
    "                logger.warning(f\"Missing expected columns: {missing_cols}\")\n",
    "            \n",
    "            if df.empty:\n",
    "                raise ValueError(\"Dataset is empty\")\n",
    "            \n",
    "            missing_stats = df.isnull().sum()\n",
    "            missing_count = missing_stats[missing_stats > 0]\n",
    "            if not missing_count.empty:\n",
    "                logger.warning(f\"Missing values found:\\n{missing_count}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        self._handle_missing_values(df_processed)\n",
    "        df_processed = self._create_datetime_features_fast(df_processed)\n",
    "        df_processed = self._clean_solar_data(df_processed)\n",
    "        df_processed = self._clean_weather_data(df_processed)\n",
    "        \n",
    "        return df_processed\n",
    "    \n",
    "    def _handle_missing_values(self, df: pd.DataFrame):\n",
    "        solar_cols = ['GHI', 'DHI', 'DNI', 'Clearsky GHI', 'Clearsky DHI', 'Clearsky DNI']\n",
    "        for col in solar_cols:\n",
    "            if col in df.columns and df[col].isnull().sum() > 0:\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "        \n",
    "        weather_numeric_cols = ['Temperature', 'Pressure', 'Relative Humidity', \n",
    "                               'Wind Speed', 'Dew Point', 'Precipitable Water']\n",
    "        for col in weather_numeric_cols:\n",
    "            if col in df.columns and df[col].isnull().sum() > 0:\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "        \n",
    "        if 'Snow Depth' in df.columns:\n",
    "            df['Snow Depth'].fillna(0, inplace=True)\n",
    "        \n",
    "        if 'Solar Zenith Angle' in df.columns and df['Solar Zenith Angle'].isnull().sum() > 0:\n",
    "            df['Solar Zenith Angle'].fillna(df['Solar Zenith Angle'].median(), inplace=True)\n",
    "    \n",
    "    def _create_datetime_features_fast(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        try:\n",
    "            df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour', 'Minute']])\n",
    "            \n",
    "            df['day_of_year'] = df['datetime'].dt.dayofyear\n",
    "            df['is_weekend'] = (df['datetime'].dt.dayofweek >= 5).astype(int)\n",
    "            \n",
    "            df['hour_angle'] = (df['Hour'] + df['Minute']/60 - 12) * 15\n",
    "            df['solar_elevation_approx'] = 90 - df.get('Solar Zenith Angle', 0)\n",
    "            \n",
    "            df['season'] = df['Month'].map({\n",
    "                12: 0, 1: 0, 2: 0,\n",
    "                3: 1, 4: 1, 5: 1,\n",
    "                6: 2, 7: 2, 8: 2,\n",
    "                9: 3, 10: 3, 11: 3\n",
    "            })\n",
    "            \n",
    "        \n",
    "            df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)\n",
    "            df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)\n",
    "            df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
    "            df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "            \n",
    "           \n",
    "            df['IsDaylight'] = ((df['Hour'] >= 6) & (df['Hour'] <= 18)).astype(int)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not create datetime features: {e}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _clean_solar_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        solar_cols = ['GHI', 'DHI', 'DNI', 'Clearsky GHI', 'Clearsky DHI', 'Clearsky DNI']\n",
    "        \n",
    "        for col in solar_cols:\n",
    "            if col in df.columns:\n",
    "                negative_mask = df[col] < 0\n",
    "                if negative_mask.sum() > 0:\n",
    "                    df.loc[negative_mask, col] = 0\n",
    "                \n",
    "                if 'GHI' in col:\n",
    "                    high_mask = df[col] > 1400\n",
    "                    if high_mask.sum() > 0:\n",
    "                        df.loc[high_mask, col] = 1400\n",
    "                \n",
    "                elif 'DNI' in col:\n",
    "                    high_mask = df[col] > 1000\n",
    "                    if high_mask.sum() > 0:\n",
    "                        df.loc[high_mask, col] = 1000\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _clean_weather_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        bounds = {\n",
    "            'Temperature': (-50, 60),\n",
    "            'Relative Humidity': (0, 100),\n",
    "            'Pressure': (900, 1100),\n",
    "            'Wind Speed': (0, 50),\n",
    "            'Dew Point': (-60, 50),\n",
    "            'Snow Depth': (0, 1000),\n",
    "            'Solar Zenith Angle': (0, 180),\n",
    "            'Precipitable Water': (0, 100)\n",
    "        }\n",
    "        \n",
    "        for col, (min_val, max_val) in bounds.items():\n",
    "            if col in df.columns:\n",
    "                outliers = (df[col] < min_val) | (df[col] > max_val)\n",
    "                if outliers.sum() > 0:\n",
    "                    df[col] = np.clip(df[col], min_val, max_val)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_target_variable(self, df: pd.DataFrame, target_type: str = 'energy_output',\n",
    "                             panel_specs: Dict = None) -> pd.DataFrame:\n",
    "        df_with_target = df.copy()\n",
    "        \n",
    "        if panel_specs is None:\n",
    "            panel_specs = {\n",
    "                'panel_area': 20,\n",
    "                'panel_efficiency': 0.20,\n",
    "                'system_efficiency': 0.85,\n",
    "                'temperature_coefficient': -0.004,\n",
    "                'optimal_temperature': 25\n",
    "            }\n",
    "        \n",
    "        if target_type == 'energy_output':\n",
    "            solar_energy = self._calculate_energy_output(df_with_target, panel_specs)\n",
    "        elif target_type == 'ghi_prediction':\n",
    "            solar_energy = self._create_ghi_prediction_target(df_with_target) #this part can be removed\n",
    "        elif target_type == 'efficiency_index':\n",
    "            solar_energy = self._calculate_efficiency_index(df_with_target)\n",
    "        else:\n",
    "            raise ValueError(\"target_type must be 'energy_output', 'ghi_prediction', or 'efficiency_index'\")\n",
    "        \n",
    "        df_with_target[self.target_column] = solar_energy\n",
    "        \n",
    "        return df_with_target\n",
    "    \n",
    "    def _calculate_energy_output(self, df: pd.DataFrame, panel_specs: Dict) -> np.ndarray:\n",
    "        if 'GHI' not in df.columns:\n",
    "            raise ValueError(\"GHI column required for energy output calculation\")\n",
    "        \n",
    "        base_energy = (df['GHI'] * panel_specs['panel_area'] * \n",
    "                      panel_specs['panel_efficiency'] / 1000)\n",
    "        \n",
    "        if 'Temperature' in df.columns:\n",
    "            temp_factor = 1 + panel_specs['temperature_coefficient'] * \\\n",
    "                         (df['Temperature'] - panel_specs['optimal_temperature'])\n",
    "            temp_factor = np.clip(temp_factor, 0.6, 1.2)\n",
    "            base_energy *= temp_factor\n",
    "        \n",
    "        energy_output = base_energy * panel_specs['system_efficiency']\n",
    "        \n",
    "        if 'Snow Depth' in df.columns:\n",
    "            snow_factor = np.where(df['Snow Depth'] > 0, \n",
    "                                 np.maximum(0.1, 1 - df['Snow Depth'] / 100), 1)\n",
    "            energy_output *= snow_factor\n",
    "        \n",
    "        if 'Wind Speed' in df.columns:\n",
    "            wind_factor = 1 + np.minimum(0.05, df['Wind Speed'] / 100)\n",
    "            energy_output *= wind_factor\n",
    "        \n",
    "        if 'Solar Zenith Angle' in df.columns:\n",
    "            angle_factor = np.where(df['Solar Zenith Angle'] > 75, \n",
    "                                   np.maximum(0.1, 1 - (df['Solar Zenith Angle'] - 75) / 50), 1)\n",
    "            energy_output *= angle_factor\n",
    "        \n",
    "        noise_factor = np.random.normal(1.0, 0.015, len(df))\n",
    "        energy_output *= noise_factor\n",
    "        \n",
    "        energy_output = np.maximum(0, energy_output)\n",
    "        \n",
    "        return energy_output\n",
    "    \n",
    "    def _create_ghi_prediction_target(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        if 'GHI' not in df.columns:\n",
    "            raise ValueError(\"GHI column required for GHI prediction target\") #This can be removed\n",
    "        \n",
    "        ghi_target = df['GHI'].copy()\n",
    "        if len(df) > 1:\n",
    "            ghi_target = df['GHI'].shift(-1).fillna(df['GHI'])\n",
    "        \n",
    "        return ghi_target.values\n",
    "    \n",
    "    def _calculate_efficiency_index(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        required_cols = ['GHI', 'Clearsky GHI']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            raise ValueError(f\"Columns {required_cols} required for efficiency index\")\n",
    "        \n",
    "        efficiency_index = df['GHI'] / (df['Clearsky GHI'] + 1e-6)\n",
    "        \n",
    "        weather_penalty = 0\n",
    "        if 'Relative Humidity' in df.columns:\n",
    "            weather_penalty += (df['Relative Humidity'] / 100) * 0.1\n",
    "        \n",
    "        efficiency_index = efficiency_index * (1 - weather_penalty)\n",
    "        efficiency_index = np.clip(efficiency_index, 0, 1.5)\n",
    "        \n",
    "        return efficiency_index * 100\n",
    "    \n",
    "    def engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_engineered = df.copy()\n",
    "        \n",
    "        # Drop columns we won't use\n",
    "        cols_to_drop = ['Month', 'Day', 'Hour', 'GHI', 'Clearsky GHI', \n",
    "                       'DHI', 'Clearsky DNI', 'DNI', 'Clearsky DHI']\n",
    "        df_engineered = df_engineered.drop(columns=[col for col in cols_to_drop if col in df_engineered.columns])\n",
    "        \n",
    "        # Create interaction features\n",
    "        if all(col in df_engineered.columns for col in ['Wind Speed', 'Temperature']):\n",
    "            df_engineered['Wind_Temp'] = df_engineered['Wind Speed'] * df_engineered['Temperature']\n",
    "        \n",
    "        if all(col in df_engineered.columns for col in ['Temperature', 'Relative Humidity']):\n",
    "            df_engineered['Temp_RelHumidity'] = df_engineered['Temperature'] * df_engineered['Relative Humidity'] / 100\n",
    "        \n",
    "        if all(col in df_engineered.columns for col in ['Wind Speed', 'Relative Humidity']):\n",
    "            df_engineered['Wind_RelHumidity'] = df_engineered['Wind Speed'] * df_engineered['Relative Humidity']\n",
    "        \n",
    "        return df_engineered\n",
    "    \n",
    "    def train_model(self, df: pd.DataFrame, test_size: float = 0.2, \n",
    "                   optimize_hyperparameters: bool = True, cv_folds: int = 3) -> Dict:\n",
    "        if self.target_column not in df.columns:\n",
    "            raise ValueError(f\"Target column '{self.target_column}' not found in DataFrame\")\n",
    "        \n",
    "        cols_to_drop = ['datetime', 'Year', 'Minute', self.target_column]\n",
    "        feature_cols = [col for col in df.columns if col not in cols_to_drop]\n",
    "        \n",
    "        X = df[feature_cols].copy()\n",
    "        y = df[self.target_column].copy()\n",
    "        \n",
    "        X = X.fillna(X.median())\n",
    "        \n",
    "        self.feature_names = list(X.columns)\n",
    "        \n",
    "        if 'datetime' in df.columns:\n",
    "            sort_idx = df['datetime'].argsort()\n",
    "            n_test = int(len(df) * test_size)\n",
    "            \n",
    "            train_idx = sort_idx[:-n_test]\n",
    "            test_idx = sort_idx[-n_test:]\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=self.random_state\n",
    "            )\n",
    "        \n",
    "        if self.model_type == 'random_forest':\n",
    "            base_model = RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                random_state=self.random_state, \n",
    "                n_jobs=-1\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
    "        \n",
    "        self.pipeline = Pipeline([\n",
    "            ('scaler', self.scaler),\n",
    "            ('regressor', base_model)\n",
    "        ])\n",
    "        \n",
    "        if optimize_hyperparameters:\n",
    "            self.pipeline = self._fast_optimize_hyperparameters(\n",
    "                self.pipeline, X_train, y_train, cv_folds\n",
    "            )\n",
    "        \n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "        self.model = self.pipeline.named_steps['regressor']\n",
    "        self.is_trained = True\n",
    "        \n",
    "        y_train_pred = self.pipeline.predict(X_train)\n",
    "        y_test_pred = self.pipeline.predict(X_test)\n",
    "        \n",
    "        self.metrics = self._calculate_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "        \n",
    "        cv_scores = cross_val_score(\n",
    "            self.pipeline, X_train, y_train, cv=cv_folds, scoring='r2', n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        self._log_model_performance(cv_scores)\n",
    "        \n",
    "        return {\n",
    "            'train_score': self.metrics.train_r2,\n",
    "            'test_score': self.metrics.r2_score,\n",
    "            'cv_scores': cv_scores,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'y_pred': y_test_pred,\n",
    "            'feature_importance': self._get_feature_importance()\n",
    "        }\n",
    "    \n",
    "    def _fast_optimize_hyperparameters(self, pipeline: Pipeline, X_train: pd.DataFrame, \n",
    "                                      y_train: pd.Series, cv_folds: int) -> Pipeline:\n",
    "        if self.model_type == 'random_forest':\n",
    "            param_distributions = {\n",
    "                'regressor__n_estimators': [50, 100, 150],\n",
    "                'regressor__max_depth': [10, 15, 20, None],\n",
    "                'regressor__min_samples_split': [2, 5, 10],\n",
    "                'regressor__min_samples_leaf': [1, 2, 4],\n",
    "                'regressor__max_features': ['sqrt', 'log2']\n",
    "            }\n",
    "        \n",
    "        n_iter = min(12, len(X_train) // 1000)\n",
    "        n_iter = max(n_iter, 6)\n",
    "        \n",
    "        random_search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions,\n",
    "            n_iter=n_iter,\n",
    "            cv=cv_folds,\n",
    "            scoring='r2',\n",
    "            n_jobs=-1,\n",
    "            verbose=0,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        logger.info(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "        logger.info(f\"Best CV score: {random_search.best_score_:.4f}\")\n",
    "        \n",
    "        return random_search.best_estimator_\n",
    "    \n",
    "    def _calculate_metrics(self, y_train: pd.Series, y_train_pred: np.ndarray,\n",
    "                      y_test: pd.Series, y_test_pred: np.ndarray) -> ModelMetrics:\n",
    "        r2 = r2_score(y_test, y_test_pred)\n",
    "        mse = mean_squared_error(y_test, y_test_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        \n",
    "        # More robust MAPE calculation that handles edge cases\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            ape = np.abs((y_test - y_test_pred) / y_test)\n",
    "            # Filter out infinite and NaN values (where y_test was 0)\n",
    "            ape = ape[np.isfinite(ape)]\n",
    "            mape = np.mean(ape) * 100 if len(ape) > 0 else 0\n",
    "        \n",
    "        \n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        overfitting = train_r2 - r2\n",
    "    \n",
    "        return ModelMetrics(\n",
    "            r2_score=r2,\n",
    "            mse=mse,\n",
    "            rmse=rmse,\n",
    "            mae=mae,\n",
    "            mape=mape,\n",
    "\n",
    "            train_r2=train_r2,\n",
    "            overfitting_score=overfitting\n",
    "        )\n",
    "    \n",
    "    def _get_feature_importance(self) -> pd.DataFrame:\n",
    "        if not self.is_trained or not hasattr(self.model, 'feature_importances_'):\n",
    "            return None\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': self.feature_names,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    def _log_model_performance(self, cv_scores: np.ndarray):\n",
    "        logger.info(\"=\"*70)\n",
    "        logger.info(\"SOLAR ENERGY MODEL PERFORMANCE SUMMARY\")\n",
    "        logger.info(\"=\"*70)\n",
    "        logger.info(f\"Model Type: {self.model_type.upper()}\")\n",
    "        logger.info(f\"Test R² Score: {self.metrics.r2_score:.4f}\")\n",
    "        logger.info(f\"Test RMSE: {self.metrics.rmse:.2f}\")\n",
    "        logger.info(f\"Test MAE: {self.metrics.mae:.2f}\")\n",
    "        logger.info(f\"Test MAPE: {self.metrics.mape:.2f}%\")\n",
    "        logger.info(f\"Cross-validation R²: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "        \n",
    "        if self.metrics.r2_score >= 0.9:\n",
    "            performance = \"EXCELLENT\"\n",
    "        elif self.metrics.r2_score >= 0.8:\n",
    "            performance = \"VERY GOOD\" \n",
    "        elif self.metrics.r2_score >= 0.7:\n",
    "            performance = \"GOOD\"\n",
    "        elif self.metrics.r2_score >= 0.6:\n",
    "            performance = \"FAIR\"\n",
    "        else:\n",
    "            performance = \"NEEDS IMPROVEMENT\"\n",
    "        \n",
    "        logger.info(f\"Performance Level: {performance}\")\n",
    "        \n",
    "        if self.metrics.overfitting_score > 0.15:\n",
    "            logger.warning(f\"HIGH overfitting detected (gap: {self.metrics.overfitting_score:.4f})\")\n",
    "        elif self.metrics.overfitting_score > 0.05:\n",
    "            logger.warning(f\"MILD overfitting detected (gap: {self.metrics.overfitting_score:.4f})\")\n",
    "        else:\n",
    "            logger.info(f\"Good generalization (train-test gap: {self.metrics.overfitting_score:.4f})\")\n",
    "        \n",
    "        logger.info(\"=\"*70)\n",
    "    \n",
    "    def predict(self, X_new: pd.DataFrame, return_confidence: bool = True) -> Dict:\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        \n",
    "        X_pred = self._prepare_prediction_features(X_new)\n",
    "        \n",
    "        predictions = self.pipeline.predict(X_pred)\n",
    "        \n",
    "        results = {\n",
    "            'predictions': predictions,\n",
    "            'input_data': X_new,\n",
    "            'features_used': X_pred\n",
    "        }\n",
    "        \n",
    "        if return_confidence and hasattr(self.model, 'estimators_'):\n",
    "            confidence_info = self._calculate_prediction_confidence(X_pred, predictions)\n",
    "            results.update(confidence_info)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _prepare_prediction_features(self, X_new: pd.DataFrame) -> pd.DataFrame:\n",
    "        missing_features = set(self.feature_names) - set(X_new.columns)\n",
    "        if missing_features:\n",
    "            logger.warning(f\"Missing features: {missing_features}\")\n",
    "            \n",
    "            for feature in missing_features:\n",
    "                if any(x in feature.lower() for x in ['_ma', '_ratio', '_diff']):\n",
    "                    X_new[feature] = 0\n",
    "                elif 'temperature' in feature.lower():\n",
    "                    X_new[feature] = 20\n",
    "                elif 'humidity' in feature.lower():\n",
    "                    X_new[feature] = 60\n",
    "                elif 'pressure' in feature.lower():\n",
    "                    X_new[feature] = 1013\n",
    "                elif 'wind' in feature.lower():\n",
    "                    X_new[feature] = 3\n",
    "                else:\n",
    "                    X_new[feature] = 0\n",
    "        \n",
    "        X_pred = X_new[self.feature_names].copy()\n",
    "        X_pred = X_pred.fillna(X_pred.median())\n",
    "        \n",
    "        return X_pred\n",
    "    \n",
    "    def _calculate_prediction_confidence(self, X_pred: pd.DataFrame, predictions: np.ndarray) -> Dict:\n",
    "        fitted_scaler = self.pipeline.named_steps['scaler']\n",
    "        \n",
    "        tree_predictions = np.array([\n",
    "            tree.predict(fitted_scaler.transform(X_pred)) \n",
    "            for tree in self.model.estimators_\n",
    "        ])\n",
    "        \n",
    "        prediction_std = np.std(tree_predictions, axis=0)\n",
    "        prediction_var = np.var(tree_predictions, axis=0)\n",
    "        \n",
    "        confidence_intervals = 1.96 * prediction_std\n",
    "        \n",
    "        max_std = np.max(prediction_std) + 1e-8\n",
    "        confidence_scores = 100 * (1 - (prediction_std / max_std))\n",
    "        confidence_scores = np.clip(confidence_scores, 0, 100)\n",
    "        \n",
    "        lower_bounds = predictions - confidence_intervals\n",
    "        upper_bounds = predictions + confidence_intervals\n",
    "        \n",
    "        return {\n",
    "            'confidence_scores': confidence_scores,\n",
    "            'prediction_std': prediction_std,\n",
    "            'prediction_variance': prediction_var,\n",
    "            'confidence_intervals': confidence_intervals,\n",
    "            'lower_bounds': lower_bounds,\n",
    "            'upper_bounds': upper_bounds\n",
    "        }\n",
    "    \n",
    "    def plot_results(self, training_results: Dict, figsize: Tuple[int, int] = (15, 10)):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before plotting results\")\n",
    "        \n",
    "        y_test = training_results['y_test']\n",
    "        y_pred = training_results['y_pred']\n",
    "        feature_importance = training_results.get('feature_importance')\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
    "        fig.suptitle(f'Solar Energy Prediction Model Results ({self.model_type.title()})', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes[0, 0].scatter(y_test, y_pred, alpha=0.6, s=20, c='orange')\n",
    "        axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "        axes[0, 0].set_xlabel('Actual Solar Energy Output')\n",
    "        axes[0, 0].set_ylabel('Predicted Solar Energy Output')\n",
    "        axes[0, 0].set_title(f'Actual vs Predicted (R² = {self.metrics.r2_score:.3f})')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        residuals = y_test - y_pred\n",
    "        axes[0, 1].scatter(y_pred, residuals, alpha=0.6, s=20, c='lightblue')\n",
    "        axes[0, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "        axes[0, 1].set_xlabel('Predicted Solar Energy Output')\n",
    "        axes[0, 1].set_ylabel('Residuals')\n",
    "        axes[0, 1].set_title('Residuals Plot')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[0, 2].hist(residuals, bins=30, alpha=0.7, color='lightgreen')\n",
    "        axes[0, 2].axvline(residuals.mean(), color='red', linestyle='--', linewidth=2,\n",
    "                          label=f'Mean: {residuals.mean():.2f}')\n",
    "        axes[0, 2].set_xlabel('Prediction Errors')\n",
    "        axes[0, 2].set_ylabel('Frequency')\n",
    "        axes[0, 2].set_title('Error Distribution')\n",
    "        axes[0, 2].legend()\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        if feature_importance is not None:\n",
    "            top_features = feature_importance.head(10)\n",
    "            y_pos = np.arange(len(top_features))\n",
    "            axes[1, 0].barh(y_pos, top_features['importance'], color='forestgreen', alpha=0.8)\n",
    "            axes[1, 0].set_yticks(y_pos)\n",
    "            axes[1, 0].set_yticklabels(top_features['feature'], fontsize=8)\n",
    "            axes[1, 0].set_xlabel('Feature Importance')\n",
    "            axes[1, 0].set_title('Top 10 Feature Importances')\n",
    "            axes[1, 0].invert_yaxis()\n",
    "            axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        cv_scores = training_results['cv_scores']\n",
    "        axes[1, 1].bar(range(len(cv_scores)), cv_scores, alpha=0.8, color='orange')\n",
    "        axes[1, 1].axhline(cv_scores.mean(), color='red', linestyle='--', linewidth=2,\n",
    "                          label=f'Mean: {cv_scores.mean():.3f}')\n",
    "        axes[1, 1].set_xlabel('CV Fold')\n",
    "        axes[1, 1].set_ylabel('R² Score')\n",
    "        axes[1, 1].set_title('Cross-Validation Scores')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1, 2].axis('off')\n",
    "        metrics_text = f\"\"\"\n",
    "MODEL PERFORMANCE\n",
    "\n",
    "R² Score: {self.metrics.r2_score:.4f}\n",
    "RMSE: {self.metrics.rmse:.2f}\n",
    "MAE: {self.metrics.mae:.2f}\n",
    "MAPE: {self.metrics.mape:.2f}%\n",
    "Accuracy: {self.metrics.accuracy_percentage:.2f}%\n",
    "\n",
    "Cross-Validation:\n",
    "   Mean R²: {cv_scores.mean():.4f}\n",
    "   Std R²: {cv_scores.std():.4f}\n",
    "\n",
    "Overfitting Check:\n",
    "   Train R²: {self.metrics.train_r2:.4f}\n",
    "   Test R²: {self.metrics.r2_score:.4f}\n",
    "   Gap: {self.metrics.overfitting_score:.4f}\n",
    "        \"\"\"\n",
    "        \n",
    "        axes[1, 2].text(0.05, 0.95, metrics_text, transform=axes[1, 2].transAxes, \n",
    "                        fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
    "        axes[1, 2].set_title('Performance Summary')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def load_model(self, filepath: Union[str, Path]):\n",
    "        filepath = Path(filepath)\n",
    "        \n",
    "        model_path = filepath.with_suffix('.pkl')\n",
    "        if not model_path.exists():\n",
    "            raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "        \n",
    "        self.pipeline = joblib.load(model_path)\n",
    "        self.model = self.pipeline.named_steps['regressor']\n",
    "        self.scaler = self.pipeline.named_steps['scaler']\n",
    "        \n",
    "        info_path = filepath.with_suffix('.json')\n",
    "        if info_path.exists():\n",
    "            import json\n",
    "            with open(info_path, 'r') as f:\n",
    "                model_info = json.load(f)\n",
    "            \n",
    "            self.model_type = model_info['model_type']\n",
    "            self.feature_names = model_info['feature_names']\n",
    "            self.target_column = model_info['target_column']\n",
    "            \n",
    "            if model_info['metrics']:\n",
    "                metrics_dict = model_info['metrics']\n",
    "                self.metrics = ModelMetrics(\n",
    "                    r2_score=metrics_dict['r2_score'],\n",
    "                    mse=0,\n",
    "                    rmse=metrics_dict['rmse'],\n",
    "                    mae=metrics_dict['mae'],\n",
    "                    mape=metrics_dict['mape'],\n",
    "                    accuracy_percentage=metrics_dict['accuracy_percentage']\n",
    "                )\n",
    "        \n",
    "        self.is_trained = True\n",
    "        logger.info(f\"Model loaded from {model_path}\")\n",
    "    \n",
    "    def generate_prediction_report(self, prediction_results: Dict, \n",
    "                                 output_file: Optional[str] = None) -> str:\n",
    "        predictions = prediction_results['predictions']\n",
    "        input_data = prediction_results['input_data']\n",
    "        \n",
    "        report_lines = [\n",
    "            \"=\"*80,\n",
    "            \"SOLAR ENERGY PREDICTION REPORT\",\n",
    "            \"=\"*80,\n",
    "            f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "            f\"Model Type: {self.model_type.title()}\",\n",
    "            f\"Target: Solar Energy Output (kWh)\",\n",
    "            \"\"\n",
    "        ]\n",
    "        \n",
    "        if self.metrics:\n",
    "            report_lines.extend([\n",
    "                \"MODEL PERFORMANCE:\",\n",
    "                \"-\" * 50,\n",
    "                f\"R² Score: {self.metrics.r2_score:.4f}\",\n",
    "                f\"RMSE: {self.metrics.rmse:.2f} kWh\",\n",
    "                f\"MAE: {self.metrics.mae:.2f} kWh\",\n",
    "                f\"MAPE: {self.metrics.mape:.2f}%\",\n",
    "                f\"Accuracy: {self.metrics.accuracy_percentage:.2f}%\",\n",
    "                \"\"\n",
    "            ])\n",
    "        \n",
    "        report_lines.extend([\n",
    "            \"PREDICTION SUMMARY:\",\n",
    "            \"-\" * 50,\n",
    "            f\"Number of predictions: {len(predictions)}\",\n",
    "            f\"Average predicted energy: {predictions.mean():.2f} kWh\",\n",
    "            f\"Energy range: {predictions.min():.2f} - {predictions.max():.2f} kWh\",\n",
    "            f\"Standard deviation: {predictions.std():.2f} kWh\",\n",
    "            f\"Total predicted energy: {predictions.sum():.2f} kWh\",\n",
    "            \"\"\n",
    "        ])\n",
    "        \n",
    "        n_show = min(10, len(predictions))\n",
    "        report_lines.extend([\n",
    "            f\"SAMPLE PREDICTIONS (showing first {n_show}):\",\n",
    "            \"-\" * 50\n",
    "        ])\n",
    "        \n",
    "        for i in range(n_show):\n",
    "            pred = predictions[i]\n",
    "            line = f\"Sample {i+1:3d}: {pred:7.2f} kWh\"\n",
    "            \n",
    "            if 'confidence_scores' in prediction_results:\n",
    "                conf = prediction_results['confidence_scores'][i]\n",
    "                line += f\" (Confidence: {conf:5.1f}%)\"\n",
    "            \n",
    "            report_lines.append(line)\n",
    "        \n",
    "        if len(predictions) > n_show:\n",
    "            report_lines.append(f\"... and {len(predictions) - n_show} more predictions\")\n",
    "        \n",
    "        report_lines.extend([\n",
    "            \"\",\n",
    "            \"PERFORMANCE INSIGHTS:\",\n",
    "            \"-\" * 50\n",
    "        ])\n",
    "        \n",
    "        if self.metrics:\n",
    "            if self.metrics.r2_score >= 0.9:\n",
    "                report_lines.append(\"EXCELLENT model performance\")\n",
    "            elif self.metrics.r2_score >= 0.8:\n",
    "                report_lines.append(\"VERY GOOD model performance\")\n",
    "            elif self.metrics.r2_score >= 0.7:\n",
    "                report_lines.append(\"GOOD model performance\")\n",
    "            else:\n",
    "                report_lines.append(\"FAIR model performance\")\n",
    "        \n",
    "        report_lines.append(\"=\"*80)\n",
    "        \n",
    "        report = \"\\n\".join(report_lines)\n",
    "        \n",
    "        if output_file:\n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write(report)\n",
    "            logger.info(f\"Report saved to {output_file}\")\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "def demo_solar_energy_workflow():\n",
    "    model = SolarEnergyPredictor(model_type='random_forest', random_state=42)\n",
    "    \n",
    "    try:\n",
    "        df = model.load_data('D:\\pict_ml_project\\Solar_DataSet_Techfest(1).csv')\n",
    "        \n",
    "        df_processed = model.preprocess_data(df)\n",
    "        \n",
    "        df_with_target = model.create_target_variable(\n",
    "            df_processed, \n",
    "            target_type='energy_output',\n",
    "            panel_specs={\n",
    "                'panel_area': 25,\n",
    "                'panel_efficiency': 0.21,\n",
    "                'system_efficiency': 0.87,\n",
    "                'temperature_coefficient': -0.0038,\n",
    "                'optimal_temperature': 25\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        df_final = model.engineer_features(df_with_target)\n",
    "        \n",
    "        training_results = model.train_model(\n",
    "            df_final,\n",
    "            test_size=0.2,\n",
    "            optimize_hyperparameters=True,\n",
    "            cv_folds=3\n",
    "        )\n",
    "        \n",
    "        model.plot_results(training_results, figsize=(15, 10))\n",
    "        \n",
    "        X_test = training_results['X_test']\n",
    "        sample_data = X_test.head(100)\n",
    "        \n",
    "        prediction_results = model.predict(sample_data, return_confidence=True)\n",
    "        \n",
    "        report = model.generate_prediction_report(prediction_results)\n",
    "        print(report)\n",
    "        \n",
    "        return model, training_results, prediction_results\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"DATASET FILE NOT FOUND!\")\n",
    "        print(\"Ensure 'Solar_DataSet_Techfest(1).csv' is in the current directory\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in workflow: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def quick_train(csv_file_path: str, sample_predictions: int = 5):\n",
    "    model = SolarEnergyPredictor(model_type='random_forest')\n",
    "    \n",
    "    df = model.load_data(csv_file_path)\n",
    "    df_processed = model.preprocess_data(df)\n",
    "    df_with_target = model.create_target_variable(df_processed, target_type='energy_output')\n",
    "    df_final = model.engineer_features(df_with_target)\n",
    "    \n",
    "    results = model.train_model(df_final, optimize_hyperparameters=False, cv_folds=3)\n",
    "    \n",
    "    X_test = results['X_test']\n",
    "    sample_data = X_test.head(100)\n",
    "    predictions = model.predict(sample_data, return_confidence=False)\n",
    "    \n",
    "    print(f\"Model R² Score: {model.metrics.r2_score:.3f}\")\n",
    "    print(f\"Model Accuracy: {model.metrics.accuracy_percentage:.1f}%\")\n",
    "    print(f\"Sample Predictions: {predictions['predictions'][:sample_predictions]}\")\n",
    "    \n",
    "    return model, predictions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_solar_energy_workflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
